Topic,Explanation
What does the model predict?,It predicts whether a client CDD report should be labeled “Rework Required” or “Satisfactory” based on the presence or absence of required review element (RE) files.
What does the model use?,It uses:• Which review elements were required (based on client’s risk factors)• Which of those were actually found in the folder• Other metadata such as % missing or total required
What will the model explain?,The model can explain why a report is flagged for rework using feature importance (e.g., “RE2 was required but missing” had high impact).
Target variable (Label),Actual Review Rating from 1LOD or corrected 2LOD label: Satisfactory or Rework Required


Required,Present,Actual Label,Interpretation
1,1,Satisfactory,Correct outcome, compliant.
1,0,Satisfactory,Red flag – bot or 1LOD likely missed a required file. Model will likely predict Rework Required.
1,0,Rework Required,Good – aligns with expectations. Model should confirm this.
0,1,Satisfactory,Extra file found – not required, but not a problem. Model may still predict satisfactory.
0,1,Rework Required,Unexpected – investigate why rework was required if everything required was present and extra documents existed.
1,1,Rework Required,Possibly correct – maybe the document was present but content was insufficient (outside scope of presence-only model).
0,0,Satisfactory,Valid – nothing required, nothing found.
0,0,Rework Required,Odd case – nothing was required, but still marked as rework. Could be manual override or other issue.

Perfect! Based on your **Excel structure** and the goal of your model, here’s a clear **interpretation guide** you can add as a new section (either in the Excel file or as a slide/doc accompanying it).

---

## **Model Interpretation Guide (Add this as a block in Excel)**

| **Topic**                  | **Explanation** |
|----------------------------|------------------|
| **What does the model predict?** | It predicts whether a client CDD report should be labeled **"Rework Required"** or **"Satisfactory"** based on the presence or absence of required review element (RE) files. |
| **What does the model use?** | It uses:<br>• Which review elements were **required** (based on client's risk factors)<br>• Which of those were actually **found** in the folder<br>• Other metadata such as % missing or total required |
| **What will the model explain?** | The model can explain **why** a report is flagged for rework using feature importance (e.g., “RE2 was required but missing” had high impact). |
| **Target variable (Label)** | `Actual Review Rating` from 1LOD or corrected 2LOD label: **Satisfactory** or **Rework Required** |

---

## **Scenario Analysis: Possible Cases**

| **Required** | **Present** | **Actual Label**     | **Interpretation**                                                                                                                                 |
|--------------|-------------|----------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|
| 1            | 1           | Satisfactory         | Correct outcome, compliant.                                                                                                                        |
| 1            | 0           | Satisfactory         | **Red flag** – bot or 1LOD likely missed a required file. Model will likely predict **Rework Required**.                                           |
| 1            | 0           | Rework Required      | Good – aligns with expectations. Model should confirm this.                                                                                        |
| 0            | 1           | Satisfactory         | Extra file found – not required, but not a problem. Model may still predict satisfactory.                                                          |
| 0            | 1           | Rework Required      | Unexpected – investigate why rework was required if everything required was present and extra documents existed.                                  |
| 1            | 1           | Rework Required      | Possibly correct – maybe the document was present but **content was insufficient** (outside scope of presence-only model).                        |
| 0            | 0           | Satisfactory         | Valid – nothing required, nothing found.                                                                                                           |
| 0            | 0           | Rework Required      | Odd case – nothing was required, but still marked as rework. Could be manual override or other issue.                                             |

---

## **How to Use This Model in Practice**

- **Input:** Flattened Excel-like row per client with required/present RE flags
- **Prediction Output:** Binary classification – "Satisfactory" or "Rework Required"
- **Confidence Score (optional):** Use model probability to rank borderline cases
- **Action:** Send reports where model disagrees with 1LOD label to 2LOD for review

---

Would you like me to append this as a **new sheet** in the Excel report we built earlier? I can format it neatly for download.



# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.optimize import minimize

# Create synthetic dataset
dates = pd.date_range(start="2020-06-30", end="2024-03-31", freq="M")
np.random.seed(42)
ff_target = np.linspace(0.25, 5.0, len(dates)) + np.random.normal(0, 0.1, len(dates))
rate = 0.5 * ff_target + np.random.normal(0, 0.2, len(dates))

df = pd.DataFrame({
    'PRD_D': dates,
    'FF_Target': ff_target,
    'RATE': rate
})

# Calculate moving average of FF_Target based on a given window
def calculate_ff_average(data, window):
    return data['FF_Target'].rolling(window=window, min_periods=1).mean()

# Generate forecasted rate using the formula
def generate_forecast(data, slope, window, start_index):
    ff_avg = calculate_ff_average(data, window)
    forecasted_rates = [data.loc[start_index - 1, 'RATE']]
    ff_avg_list = []

    for t in range(start_index, len(data)):
        prev_ff_avg = ff_avg.iloc[t - 1]
        curr_ff_avg = ff_avg.iloc[t]
        prev_forecast = forecasted_rates[-1]
        ff_avg_list.append(curr_ff_avg)

        if prev_ff_avg == 0 or curr_ff_avg == 0 or prev_forecast == 0:
            forecasted_value = prev_forecast
        else:
            log_change = np.log(curr_ff_avg) - np.log(prev_ff_avg)
            forecasted_value = np.exp(log_change * slope + np.log(prev_forecast))

        forecasted_rates.append(forecasted_value)

    forecast_df = data.iloc[start_index:].copy()
    forecast_df['Forecast'] = forecasted_rates[1:]
    forecast_df['FF_Avg'] = ff_avg_list
    return forecast_df

# Compute deposit beta (regression slope between forecast and FF average)
def compute_deposit_beta(forecast_df):
    x = forecast_df['FF_Avg'].values
    y = forecast_df['Forecast'].values
    if len(x) < 2 or np.all(x == x[0]):
        return 0
    x_mean = np.mean(x)
    y_mean = np.mean(y)
    numerator = np.sum((x - x_mean) * (y - y_mean))
    denominator = np.sum((x - x_mean) ** 2)
    return numerator / denominator if denominator != 0 else 0

# Objective function to minimize (MAE between forecasted and actual rate)
def optimize_mae(slope, data, window, start_index):
    forecast_df = generate_forecast(data, slope[0], window, start_index)
    mae = mean_absolute_error(forecast_df['RATE'], forecast_df['Forecast'])
    return mae

# Constraints to keep deposit beta within [0, 1]
def deposit_beta_bounds(slope, data, window, start_index):
    forecast_df = generate_forecast(data, slope[0], window, start_index)
    beta = compute_deposit_beta(forecast_df)
    return [beta, 1 - beta]

# Forecast initialization
start_date = pd.to_datetime("2022-02-28")
start_index = df.index[df['PRD_D'] == start_date][0]
initial_rate = df.loc[:start_index, 'RATE'].mean()
df.at[start_index - 1, 'RATE'] = initial_rate

# Run optimization for each window size
results = []

for window in range(1, 13):
    constraints = ({
        'type': 'ineq',
        'fun': lambda s, df=df, window=window, start_index=start_index: deposit_beta_bounds(s, df, window, start_index)[0]
    }, {
        'type': 'ineq',
        'fun': lambda s, df=df, window=window, start_index=start_index: deposit_beta_bounds(s, df, window, start_index)[1]
    })

    res = minimize(
        optimize_mae, x0=[0.5],
        args=(df, window, start_index),
        constraints=constraints,
        method='SLSQP'
    )

    best_slope = res.x[0]
    forecast_df = generate_forecast(df, best_slope, window, start_index)
    mae = mean_absolute_error(forecast_df['RATE'], forecast_df['Forecast'])
    rmse = mean_squared_error(forecast_df['RATE'], forecast_df['Forecast'], squared=False)
    beta = compute_deposit_beta(forecast_df)
    results.append((window, best_slope, beta, mae, rmse))

# Display final results
results_df = pd.DataFrame(results, columns=['Window', 'Best Slope', 'Avg Deposit Beta', 'MAE', 'RMSE'])
import ace_tools as tools; tools.display_dataframe_to_user(name="Forecast Optimization Results", dataframe=results_df)









# Reimport necessary modules after error
import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.optimize import minimize

# Recreate the original dataset
dates = pd.date_range(start="2020-06-30", end="2024-03-31", freq="M")
np.random.seed(42)
ff_target = np.linspace(0.25, 5.0, len(dates)) + np.random.normal(0, 0.1, len(dates))
rate = 0.5 * ff_target + np.random.normal(0, 0.2, len(dates))

df = pd.DataFrame({
    'PRD_D': dates,
    'FF_Target': ff_target,
    'RATE': rate
})

# Helper functions
def compute_ff_avg(data, window):
    return data['FF_Target'].rolling(window=window, min_periods=1).mean()

def forecast_rate_corrected(df, slope, window, start_idx):
    ff_avg = compute_ff_avg(df, window)
    forecast = [df.loc[start_idx-1, 'RATE']]
    ff_avg_used = []

    for t in range(start_idx, len(df)):
        prev_ff_avg = ff_avg.iloc[t - 1]
        curr_ff_avg = ff_avg.iloc[t]
        prev_forecast = forecast[-1]
        ff_avg_used.append(curr_ff_avg)

        if prev_ff_avg == 0 or curr_ff_avg == 0 or prev_forecast == 0:
            forecasted_value = prev_forecast
        else:
            log_change = np.log(curr_ff_avg) - np.log(prev_ff_avg)
            forecasted_value = np.exp(log_change * slope + np.log(prev_forecast))

        forecast.append(forecasted_value)

    df_forecast = df.iloc[start_idx:].copy()
    df_forecast['Forecast'] = forecast[1:]
    df_forecast['FF_Avg'] = ff_avg_used
    return df_forecast

def average_deposit_beta(df_forecast):
    x = df_forecast['FF_Avg'].values
    y = df_forecast['Forecast'].values
    if len(x) < 2 or np.all(x == x[0]):
        return 0
    x_mean = np.mean(x)
    y_mean = np.mean(y)
    numerator = np.sum((x - x_mean) * (y - y_mean))
    denominator = np.sum((x - x_mean) ** 2)
    return numerator / denominator if denominator != 0 else 0

def objective_with_beta_constraint(slope, df, window, start_idx):
    df_forecast = forecast_rate_corrected(df, slope[0], window, start_idx)
    mae = mean_absolute_error(df_forecast['RATE'], df_forecast['Forecast'])
    return mae

def beta_constraint(slope, df, window, start_idx):
    df_forecast = forecast_rate_corrected(df, slope[0], window, start_idx)
    beta = average_deposit_beta(df_forecast)
    return [beta, 1 - beta]

# Set start point
start_date = pd.to_datetime("2022-02-28")
start_idx = df.index[df['PRD_D'] == start_date][0]
initial_forecast = df.loc[:start_idx, 'RATE'].mean()
df.at[start_idx-1, 'RATE'] = initial_forecast

# Run optimization
constrained_results = []

for window in range(1, 13):
    constraints = ({
        'type': 'ineq',
        'fun': lambda s, df=df, window=window, start_idx=start_idx: beta_constraint(s, df, window, start_idx)[0]
    }, {
        'type': 'ineq',
        'fun': lambda s, df=df, window=window, start_idx=start_idx: beta_constraint(s, df, window, start_idx)[1]
    })

    res = minimize(
        objective_with_beta_constraint, x0=[0.5],
        args=(df, window, start_idx),
        constraints=constraints,
        method='SLSQP'
    )

    best_slope = res.x[0]
    df_forecast = forecast_rate_corrected(df, best_slope, window, start_idx)
    mae = mean_absolute_error(df_forecast['RATE'], df_forecast['Forecast'])
    rmse = mean_squared_error(df_forecast['RATE'], df_forecast['Forecast'], squared=False)
    avg_beta = average_deposit_beta(df_forecast)
    constrained_results.append((window, best_slope, avg_beta, mae, rmse))

# Display results
constrained_results_df = pd.DataFrame(
    constrained_results,
    columns=['Window', 'Best Slope', 'Avg Deposit Beta', 'MAE', 'RMSE']
)
import ace_tools as tools; tools.display_dataframe_to_user(name="Slope Optimization with Beta Constraint", dataframe=constrained_results_df)







import pandas as pd
import numpy as np
from datetime import datetime
from dateutil.relativedelta import relativedelta
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.optimize import minimize

# 1. Create sample data from June 30, 2020 to March 31, 2024
dates = pd.date_range(start="2020-06-30", end="2024-03-31", freq="M")
np.random.seed(42)

# Simulate FF Target with an upward trend
ff_target = np.linspace(0.25, 5.0, len(dates)) + np.random.normal(0, 0.1, len(dates))

# Simulate actual RATE with some lagged relationship to FF Target
rate = 0.5 * ff_target + np.random.normal(0, 0.2, len(dates))

# Create DataFrame
df = pd.DataFrame({
    'PRD_D': dates,
    'FF_Target': ff_target,
    'RATE': rate
})

# 2. Define function to calculate FF average based on window
def compute_ff_avg(data, window):
    return data['FF_Target'].rolling(window=window, min_periods=1).mean()

# 3. Forecasting function
def forecast_rate(df, slope, window, start_idx):
    ff_avg = compute_ff_avg(df, window)
    forecast = [df.loc[start_idx-1, 'RATE']]  # initial forecast is avg of past actuals

    for t in range(start_idx, len(df)):
        prev_ff_avg = ff_avg.iloc[t - 1]
        curr_ff_avg = ff_avg.iloc[t]

        if prev_ff_avg == 0 or curr_ff_avg == 0:
            change = 0
        else:
            log_change = np.log(curr_ff_avg / prev_ff_avg)
            change = np.exp(log_change * slope)

        forecasted_value = forecast[-1] + change
        forecast.append(forecasted_value)

    df_forecast = df.iloc[start_idx:].copy()
    df_forecast['Forecast'] = forecast[1:]
    return df_forecast

# 4. Objective function for optimization
def objective(slope, df, window, start_idx):
    df_forecast = forecast_rate(df, slope[0], window, start_idx)
    mae = mean_absolute_error(df_forecast['RATE'], df_forecast['Forecast'])
    return mae

# 5. Run optimization for window sizes 1 to 12
results = []

# Define the start index (February 2022 onwards)
start_date = pd.to_datetime("2022-02-28")
start_idx = df.index[df['PRD_D'] == start_date][0]

# Initialize the initial forecast as avg of all actuals up to Feb 2022
initial_forecast = df.loc[:start_idx, 'RATE'].mean()
df.at[start_idx-1, 'RATE'] = initial_forecast  # overwrite RATE at start_idx-1 for initial seed

for window in range(1, 13):
    res = minimize(
        objective, x0=[0.5], args=(df, window, start_idx),
        bounds=[(0, 1)], method='L-BFGS-B'
    )
    best_slope = res.x[0]
    df_forecast = forecast_rate(df, best_slope, window, start_idx)
    mae = mean_absolute_error(df_forecast['RATE'], df_forecast['Forecast'])
    rmse = mean_squared_error(df_forecast['RATE'], df_forecast['Forecast'], squared=False)
    results.append((window, best_slope, mae, rmse))

# Create results DataFrame
results_df = pd.DataFrame(results, columns=['Window', 'Best Slope', 'MAE', 'RMSE'])
import ace_tools as tools; tools.display_dataframe_to_user(name="Window Optimization Results", dataframe=results_df)





# Re-import necessary packages after code execution state reset
import pandas as pd
import numpy as np
from datetime import datetime
from dateutil.relativedelta import relativedelta
from sklearn.metrics import mean_absolute_error, mean_squared_error
from scipy.optimize import minimize

# 1. Create sample data from June 30, 2020 to March 31, 2024
dates = pd.date_range(start="2020-06-30", end="2024-03-31", freq="M")
np.random.seed(42)

# Simulate FF Target with an upward trend
ff_target = np.linspace(0.25, 5.0, len(dates)) + np.random.normal(0, 0.1, len(dates))

# Simulate actual RATE with some lagged relationship to FF Target
rate = 0.5 * ff_target + np.random.normal(0, 0.2, len(dates))

# Create DataFrame
df = pd.DataFrame({
    'PRD_D': dates,
    'FF_Target': ff_target,
    'RATE': rate
})

# Define function to calculate FF average based on window
def compute_ff_avg(data, window):
    return data['FF_Target'].rolling(window=window, min_periods=1).mean()

# Updated forecast function with corrected multiplicative formula
def forecast_rate_corrected(df, slope, window, start_idx):
    ff_avg = compute_ff_avg(df, window)
    forecast = [df.loc[start_idx-1, 'RATE']]  # initial forecast is avg of past actuals

    for t in range(start_idx, len(df)):
        prev_ff_avg = ff_avg.iloc[t - 1]
        curr_ff_avg = ff_avg.iloc[t]
        prev_forecast = forecast[-1]

        if prev_ff_avg == 0 or curr_ff_avg == 0 or prev_forecast == 0:
            forecasted_value = prev_forecast  # hold value if division/log fails
        else:
            log_change = np.log(curr_ff_avg) - np.log(prev_ff_avg)
            forecasted_value = np.exp(log_change * slope + np.log(prev_forecast))

        forecast.append(forecasted_value)

    df_forecast = df.iloc[start_idx:].copy()
    df_forecast['Forecast'] = forecast[1:]
    return df_forecast

# Updated objective function with corrected forecast
def objective_corrected(slope, df, window, start_idx):
    df_forecast = forecast_rate_corrected(df, slope[0], window, start_idx)
    mae = mean_absolute_error(df_forecast['RATE'], df_forecast['Forecast'])
    return mae

# Define the start index (February 2022 onwards)
start_date = pd.to_datetime("2022-02-28")
start_idx = df.index[df['PRD_D'] == start_date][0]

# Initialize the initial forecast as avg of all actuals up to Feb 2022
initial_forecast = df.loc[:start_idx, 'RATE'].mean()
df.at[start_idx-1, 'RATE'] = initial_forecast  # overwrite RATE at start_idx-1 for initial seed

# Rerun optimization for window sizes 1 to 12 with corrected forecast formula
corrected_results = []

for window in range(1, 13):
    res = minimize(
        objective_corrected, x0=[0.5], args=(df, window, start_idx),
        bounds=[(0, 1)], method='L-BFGS-B'
    )
    best_slope = res.x[0]
    df_forecast = forecast_rate_corrected(df, best_slope, window, start_idx)
    mae = mean_absolute_error(df_forecast['RATE'], df_forecast['Forecast'])
    rmse = mean_squared_error(df_forecast['RATE'], df_forecast['Forecast'], squared=False)
    corrected_results.append((window, best_slope, mae, rmse))

# Display updated results
import ace_tools as tools; tools.display_dataframe_to_user(name="Corrected Forecast Results", dataframe=pd.DataFrame(corrected_results, columns=['Window', 'Best Slope', 'MAE', 'RMSE']))