t0_df = window_data.sort_values('prd_d').groupby('merged_src_ip_id').first().reset_index()
t0_df = t0_df[t0_df['commitments_amt'] > 500_000]  # Apply the filter here


agg_df = df.groupby(['merged_src_ip_id', 'prd_d']).agg({
    'commitments_amt': 'sum',  # total commitments across facilities
    'CCAR_NON_ACCRL_FLAG': 'max',  # default if any facility defaults
    'MODELING_SEGMENT': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],
    'RISK_RATING': 'mean',  # or mode or first if ordinal
    'outstandings_amt': 'sum',  # total outstandings across facilities
    'day_past_due': 'mean',  # or max depending on business logic
    'int_rate_apr': 'mean'  # average interest rate
}).reset_index()

import pandas as pd
from scipy.stats import mannwhitneyu

# ----------------------------------------
# STEP 1: PREPROCESSING
# ----------------------------------------

def preprocess(df):
    # Convert 'Y'/'N' flag to binary
    df = df.copy()
    df['CCAR_NON_ACCRL_FLAG'] = df['CCAR_NON_ACCRL_FLAG'].map({'Y': 1, 'N': 0})
    df['prd_d'] = pd.to_datetime(df['prd_d'])
    return df

# ----------------------------------------
# STEP 2: CREATE T₀ SNAPSHOT PER OBLIGOR
# ----------------------------------------

def create_t0_snapshot(df):
    df_sorted = df.sort_values(['merged_src_ip_id', 'prd_d'])
    t0_df = df_sorted.groupby('merged_src_ip_id').first().reset_index()
    return t0_df

# ----------------------------------------
# STEP 3: LABEL DEFAULT WITHIN 12 MONTHS
# ----------------------------------------

def label_default_within_12m(df, t0_df):
    df_merged = df.merge(
        t0_df[['merged_src_ip_id', 'prd_d']],
        on='merged_src_ip_id',
        how='left',
        suffixes=('', '_t0')
    )
    df_merged['within_12m'] = (
        (df_merged['prd_d'] > df_merged['prd_d_t0']) &
        (df_merged['prd_d'] <= df_merged['prd_d_t0'] + pd.DateOffset(months=12))
    )
    default_within_window = (
        df_merged[df_merged['within_12m']]
        .groupby('merged_src_ip_id')['CCAR_NON_ACCRL_FLAG']
        .max()
        .reset_index()
        .rename(columns={'CCAR_NON_ACCRL_FLAG': 'default_within_12m'})
    )
    return t0_df.merge(default_within_window, on='merged_src_ip_id', how='left').fillna({'default_within_12m': 0})

# ----------------------------------------
# STEP 4: SEGMENT COMMITMENTS AND RUN TESTS
# ----------------------------------------

def run_segment_tests(agg_df, variable_list):
    agg_df = agg_df.copy()
    agg_df['commitment_segment'] = agg_df['commitments_amt'].apply(lambda x: '≤3MM' if x <= 3_000_000 else '>3MM')
    result_rows = []

    for var in variable_list:
        group1 = agg_df[agg_df['commitment_segment'] == '≤3MM'][var].dropna()
        group2 = agg_df[agg_df['commitment_segment'] == '>3MM'][var].dropna()

        # Mann–Whitney U Test (non-parametric)
        stat, p = mannwhitneyu(group1, group2, alternative='two-sided')
        result_rows.append({
            'Variable': var,
            '≤3MM Mean': round(group1.mean(), 2),
            '>3MM Mean': round(group2.mean(), 2),
            'Test': 'Mann–Whitney U',
            'p-value': round(p, 5),
            'Significant (<0.05)?': '✅' if p < 0.05 else '❌'
        })

    return pd.DataFrame(result_rows)

# ----------------------------------------
# FULL PIPELINE FUNCTION
# ----------------------------------------

def process_commitment_segmentation(df):
    df_clean = preprocess(df)
    t0_df = create_t0_snapshot(df_clean)
    agg_df = label_default_within_12m(df_clean, t0_df)
    variable_list = ['RISK_RATING', 'outstandings_amt', 'day_past_due', 'int_rate_apr']
    results_df = run_segment_tests(agg_df, variable_list)
    return agg_df, results_df

# ----------------------------------------
# USAGE EXAMPLE (after loading your data)
# ----------------------------------------

# df = pd.read_csv("your_panel_data.csv")
# agg_df, results_df = process_commitment_segmentation(df)
# print(results_df)