
	•	Vertex AI Search
Usage-based pricing (per query + indexed data); cost scales linearly with query volume and enabled features, but no always-on infrastructure cost.
	•	Vertex AI RAG Engine
Costs driven by underlying retrieval backend (Vertex AI Search or Vector Search) plus LLM usage; limited ability to independently optimize retrieval cost.
	•	Vertex AI Vector Search
Infrastructure-based pricing (always-on index serving + storage); higher fixed cost but significantly lower marginal cost at moderate to high query volumes

Vertex AI Search
Limited control over chunking; document parsing and chunking are largely managed by the service with coarse configuration options, not fully customizable per strategy.
	•	Vertex AI Vector Search
Full control over chunking; users define and manage all chunking strategies (fixed, document-aware, LLM-based, or custom) prior to embedding and indexing.
	•	Vertex AI RAG Engine
Moderate control over chunking; supports configurable chunk sizes and overlap during ingestion, but advanced or custom chunking strategies require pre-processing outside the engine.

Supports “bring your own chunks” (preview, allowlisted), allowing externally pre-chunked documents to be indexed;



	•	Vertex AI Search
Supports rich, expressive metadata filtering using query-time filter expressions across all indexed filterable fields (AND/OR/NOT, ranges, field comparisons).
	•	Vertex AI Vector Search
Supports structured, exact-match metadata filtering via pre-indexed restrict namespaces and numeric constraints; no free-form query expressions.
	•	Vertex AI RAG Engine
Limited metadata filtering; does not expose Vertex AI Search filter expressions—filtering must be approximated via corpus partitioning or file-level selection.



 Vertex AI Search vs Vector Search — Cost Comparison (Apples-to-Apples)

This document compares **Vertex AI Search (Discovery Engine)** and **Vertex AI Vector Search** on a **common workload** to understand real pricing differences.

---

## Common Ground Assumptions

Same assumptions for both services:

- **Queries:** 10 million searches per year  
  ≈ 0.32 QPS average, ~5–10 QPS peak
- **Corpus size:** ~100 GB text data  
  → ~20 million chunks / vectors
- **Embedding dimension:** 256
- **Region:** us-central1
- **No advanced generative answers**
- **Pure retrieval** (LLM calls handled separately)

---

## 1. Vertex AI Search (Discovery Engine)

### A. Query Cost
- Pricing: **$1.50 per 1,000 queries**

```
10,000,000 / 1,000 × $1.50
= $15,000 / year
```

---

### B. Index Storage Cost
- Pricing: **$5 per GB per month**
- Free tier: **10 GB**
- Billable storage: **90 GB**

```
90 GB × $5 × 12 months
= $5,400 / year
```

---

### C. Total Vertex AI Search Cost

```
$15,000 (queries)
+ $5,400 (index storage)
= $20,400 / year
≈ $1,700 / month
```

**Includes:**
- Hybrid keyword + semantic retrieval
- Ranking and relevance tuning
- Metadata filtering
- Fully managed infrastructure (no VMs to manage)

---

## 2. Vertex AI Vector Search

Closest matching pricing example from official docs:

- **20 million vectors**
- **256 dimensions**
- **~500 QPS capacity**
- **Machine type:** e2-highmem-16
- **Nodes:** 2
- **Serving cost:** ~$1,477 / month

> Note: Vector Search must be provisioned for **peak capacity**, not average QPS.

---

### A. Serving Cost

```
$1,477 × 12
= $17,724 / year
```

---

### B. Index Build / Update Cost

- Pricing: **$3 per GiB per index update**
- Assume: 100 GB index
- Assume: 1 rebuild per month

```
100 GB × $3 × 12
= $3,600 / year
```

---

### C. Total Vector Search Cost

```
$17,724 (serving)
+ $3,600 (index builds)
= $21,324 / year
≈ $1,775 / month
```

---

## Side-by-Side Summary

| Service | Annual Cost | Monthly Cost |
|------|-----------|-------------|
| Vertex AI Search | ~$20,400 | ~$1,700 |
| Vector Search | ~$21,324 | ~$1,775 |

---

## Key Takeaways

- **Low QPS (<10–20 QPS):** Vertex AI Search is cheaper or equal
- **Medium QPS (50–100 QPS):** Vector Search becomes cheaper
- **High QPS (100+ QPS):** Vector Search is dramatically cheaper

---

## Mental Model

- **Vertex AI Search**  
  SaaS-style pricing: pay per query + indexed data

- **Vector Search**  
  Infrastructure-style pricing: pay for always-on capacity

---

## Recommendation

- Choose **Vertex AI Search** for:
  - Low traffic
  - Rich metadata filtering
  - Search-style applications

- Choose **Vector Search** for:
  - High-QPS RAG
  - Embedding-heavy retrieval
  - Hybrid dense + sparse search
